{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDrugDomain Training Script\n",
    "This notebook provides an example script for training a model using the DeepDrugDomain package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Importing necessary Python libraries and modules from DeepDrugDomain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from deepdrugdomain.optimizers.factory import OptimizerFactory\n",
    "from deepdrugdomain.schedulers.factory import SchedulerFactory\n",
    "from deepdrugdomain.data.collate import CollateFactory\n",
    "from torch.utils.data import DataLoader\n",
    "from deepdrugdomain.models.factory import ModelFactory\n",
    "from dgllife.utils import CanonicalAtomFeaturizer\n",
    "import deepdrugdomain as ddd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Settings\n",
    "Set up the configuration for data paths, model parameters, and other settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'device': 'cpu',  # 'gpu' if CUDA is available and desired\n",
    "    'seed': 4,\n",
    "    'resume': '',\n",
    "    'start_epoch': 0,\n",
    "    'eval': False,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 32,\n",
    "    'pin_mem': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Environment\n",
    "seeding all the random actions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed \n",
    "seed = config['seed']\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Preprocessing functions\n",
    "this part is different for each model based on the author's preprocessing in the original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "This way of creating the model, creates the model with default hyperparameter and layers. you can see the default in the config folder of the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "model = ModelFactory.create(\"attentionsitedti\") # you can change the model to other models in the model factory (e.g. \"attentionsitedti\", \"fragxsite\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_drug, preprocess_protein, preprocess_label = model.get_preprocess(\"SMILES\", \"pdb_id\", \"Label\")\n",
    "preprocesses = preprocess_drug + preprocess_protein + preprocess_label\n",
    "collate_fn = model.collate\n",
    "\n",
    "print(preprocesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the data\n",
    "defining datasets and managing splits and creating dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = ddd.data.DatasetFactory.create(\n",
    "    \"human\", # you should change the dataset name to your dataset name in the dataset factory (e.g. \"human\", \"drugbank\", \"celegans\")\n",
    "    file_paths=\"data/human/\", # you should change the file_paths to the path of your dataset\n",
    "    preprocesses=preprocesses) \n",
    "datasets = dataset(split_method=\"random_split\", # you can change the split_method to other split methods in the dataset factory (e.g. \"random_split\", \"scaffold_split\", \"cold_split\")\n",
    "                   frac=[0.8, 0.1, 0.1],\n",
    "                   seed=seed)\n",
    "\n",
    "data_loader_train = DataLoader(datasets[0], batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'], pin_memory=config['pin_mem'],\n",
    "                               collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "data_loader_val = DataLoader(datasets[1], batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'], pin_memory=config['pin_mem'],\n",
    "                               collate_fn=collate_fn, drop_last=True)\n",
    "data_loader_test = DataLoader(datasets[2], batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'], pin_memory=config['pin_mem'],\n",
    "                               collate_fn=collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss() # you can change the criterion to other loss functions\n",
    "optimizer = OptimizerFactory.create(\n",
    "    \"adamw\", model.parameters(), lr=1e-3, weight_decay=0.0) # you can change the optimizer to other optimizers in the optimizer factory\n",
    "scheduler = SchedulerFactory.create(\n",
    "    \"cosine\", optimizer, warmup_epochs=0, warmup_lr=1e-3, num_epochs=200) # you can change the scheduler to other schedulers in the scheduler factory\n",
    "device = torch.device(config['device'])\n",
    "model.to(device)\n",
    "\n",
    "# Evaluators\n",
    "train_evaluator = ddd.metrics.Evaluator([\"accuracy_score\"], threshold=0.5) # you can change the metrics to other metrics in the  metric factory\n",
    "test_evaluator = ddd.metrics.Evaluator(\n",
    "    [\"accuracy_score\", \"f1_score\", \"auc\", \"precision_score\", \"recall_score\"], threshold=0.5) # you can change the metrics to other metrics in the metric factory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "accum_iter = 1\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    model.train_one_epoch(data_loader_train, device, criterion,\n",
    "                          optimizer, num_epochs=200, scheduler=scheduler, evaluator=train_evaluator, grad_accum_steps=accum_iter)\n",
    "    print(model.evaluate(data_loader_val, device, criterion, evaluator=test_evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data_loader_test, device, criterion, evaluator=test_evaluator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
